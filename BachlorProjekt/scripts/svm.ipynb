{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need these in this file:\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import numpy as np # linear algebra\n",
    "import get_lodging_scores\n",
    "import load_read_name_extractor as lrne\n",
    "import SVM_classifier_general as svm_general\n",
    "import pickle\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import glob\n",
    "import tracemalloc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = [\n",
    "\"Features\\hog_features_(64, 128, 3)_cells_(8, 8)_block_(1, 1)_norm_L2.npy\",\n",
    "\"Features\\hog_features_(64, 128, 3)_cells_(8, 8)_block_(2, 2)_norm_L2.npy\",\n",
    "\"Features\\hog_features_(64, 128, 3)_cells_(8, 8)_block_(3, 3)_norm_L2.npy\",\n",
    "\"Features\\hog_features_(64, 128, 3)_cells_(8, 8)_block_(4, 4)_norm_L2.npy\",\n",
    "\"Features\\hog_features_(96, 192, 3)_cells_(8, 8)_block_(1, 1)_norm_L2.npy\",\n",
    "\"Features\\hog_features_(96, 192, 3)_cells_(8, 8)_block_(2, 2)_norm_L2.npy\",\n",
    "\"Features\\hog_features_(96, 192, 3)_cells_(8, 8)_block_(3, 3)_norm_L2.npy\",\n",
    "\"Features\\img_names_(64, 128, 3)_cells_(8, 8)_block_(1, 1)_norm_L2.npy\",\n",
    "\"Features\\img_names_(64, 128, 3)_cells_(8, 8)_block_(2, 2)_norm_L2.npy\",\n",
    "\"Features\\img_names_(64, 128, 3)_cells_(8, 8)_block_(3, 3)_norm_L2.npy\",\n",
    "\"Features\\img_names_(64, 128, 3)_cells_(8, 8)_block_(4, 4)_norm_L2.npy\",\n",
    "\"Features\\img_names_(96, 192, 3)_cells_(8, 8)_block_(1, 1)_norm_L2.npy\",\n",
    "\"Features\\img_names_(96, 192, 3)_cells_(8, 8)_block_(2, 2)_norm_L2.npy\",\n",
    "\"Features\\img_names_(96, 192, 3)_cells_(8, 8)_block_(3, 3)_norm_L2.npy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_paths = data_paths[0:7]\n",
    "names_paths = data_paths[7:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_paths =    [\n",
    "                    \"Features\\hog_features_(64, 128, 3)_cells_(8, 8)_block_(5, 5)_norm_L2.npy\",\n",
    "                    \"Features\\hog_features_(64, 128, 3)_cells_(8, 8)_block_(6, 6)_norm_L2.npy\",\n",
    "                    \"Features\\hog_features_(96, 192, 3)_cells_(8, 8)_block_(5, 5)_norm_L2.npy\",\n",
    "                    \"Features\\hog_features_(96, 192, 3)_cells_(8, 8)_block_(6, 6)_norm_L2.npy\"\n",
    "                    ]\n",
    "names_paths =       [\n",
    "                    \"Features\\img_names_(64, 128, 3)_cells_(8, 8)_block_(5, 5)_norm_L2.npy\",\n",
    "                    \"Features\\img_names_(64, 128, 3)_cells_(8, 8)_block_(6, 6)_norm_L2.npy\",\n",
    "                    \"Features\\img_names_(96, 192, 3)_cells_(8, 8)_block_(5, 5)_norm_L2.npy\",\n",
    "                    \"Features\\img_names_(96, 192, 3)_cells_(8, 8)_block_(6, 6)_norm_L2.npy\"\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths_auto = glob.glob(\"Features/*npy\")\n",
    "size = int(len(data_paths_auto)/2)\n",
    "features_paths = data_paths_auto[0:size]\n",
    "names_paths = data_paths_auto[size:len(data_paths_auto)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_paths = [\n",
    " 'Features\\\\hog_features_(155, 543, 3)_cells_(8, 8)_block_(1, 1)_norm_L2.npy',\n",
    " 'Features\\\\hog_features_(155, 543, 3)_cells_(8, 8)_block_(2, 2)_norm_L2.npy',\n",
    " 'Features\\\\hog_features_(155, 543, 3)_cells_(8, 8)_block_(3, 3)_norm_L2.npy',\n",
    " 'Features\\\\hog_features_(155, 543, 3)_cells_(8, 8)_block_(4, 4)_norm_L2.npy',\n",
    " 'Features\\\\hog_features_(155, 543, 3)_cells_(8, 8)_block_(5, 5)_norm_L2.npy',\n",
    " 'Features\\\\hog_features_(155, 543, 3)_cells_(8, 8)_block_(6, 6)_norm_L2.npy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_paths = [\n",
    " 'Features\\\\img_names_(155, 543, 3)_cells_(8, 8)_block_(1, 1)_norm_L2.npy',\n",
    " 'Features\\\\img_names_(155, 543, 3)_cells_(8, 8)_block_(2, 2)_norm_L2.npy',\n",
    " 'Features\\\\img_names_(155, 543, 3)_cells_(8, 8)_block_(3, 3)_norm_L2.npy',\n",
    " 'Features\\\\img_names_(155, 543, 3)_cells_(8, 8)_block_(4, 4)_norm_L2.npy',\n",
    " 'Features\\\\img_names_(155, 543, 3)_cells_(8, 8)_block_(5, 5)_norm_L2.npy',\n",
    " 'Features\\\\img_names_(155, 543, 3)_cells_(8, 8)_block_(6, 6)_norm_L2.npy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42768,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_load = np.load(features_paths[5], allow_pickle=True)\n",
    "features_load[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results, path):\n",
    "    path = path.replace(\"Features\\\\\", \"\")\n",
    "    path = \"results/\" + path.replace(\".npy\", \".txt\")\n",
    "    with open(path, 'a') as f:\n",
    "        f.write(results)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(bin_size):\n",
    "    labels = get_lodging_scores.get_labels(bin_size)\n",
    "    #COnverts into set (no dublicates in set)\n",
    "    my_set = set(map(tuple, labels))\n",
    "    # convert set back to list of arrays\n",
    "    labels = list(map(np.array, my_set))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(data_frame, percentage):\n",
    "    partition = int(len(data_frame)*percentage/100)\n",
    "    print(len(data_frame.shape), 2)\n",
    "    print(len(data_frame[0].shape), 2)\n",
    "    x_train, x_test = data_frame[:partition,:-1],  data_frame[partition:,:-1]\n",
    "    y_train, y_test = data_frame[:partition,-1:].ravel() , data_frame[partition:,-1:].ravel()\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(filename, clf):\n",
    "    filename = filename.replace(\"Features\\\\\", \"\")\n",
    "    filename = \"model/\" + filename.replace(\".npy\", \".sav\")\n",
    "    pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mult_models(features_paths, names_paths, bin_size = 10, svm_kernel=\"rbf\", class_weights = None):\n",
    "    for i in range (len(features_paths)):\n",
    "        \n",
    "\n",
    "        #laod features and names\n",
    "        features_load = np.load(features_paths[i], allow_pickle=True)\n",
    "        names_load = np.load(names_paths[i], allow_pickle=True)\n",
    "        #load labels\n",
    "        labels = load_labels(bin_size)\n",
    "        #convert names into [flight_folder, ROI]\n",
    "        names = lrne.it_name_extract_labels_from_img_jpeg(names_load)\n",
    "        names_load = None\n",
    "        #match labels with feature names\n",
    "        index = svm_general.match_pic_label_to_names(features_load, labels, names)\n",
    "        data_frame = [list(row) for row in features_load]\n",
    "        features_load = None\n",
    "\n",
    "        for i in range(len(index)):\n",
    "            data_frame[index[i]].append(labels[i][3])\n",
    "        labels = None\n",
    "        names = None\n",
    "        print(len(data_frame), 0)\n",
    "        print(len(data_frame[0]), 0)\n",
    "\n",
    "        #shuffle data and convert to array\n",
    "        #np.random.shuffle(data_frame)\n",
    "\n",
    "        #partition data\n",
    "        percentage = 80\n",
    "        data_frame = np.array(data_frame)\n",
    "        x_train, x_test, y_train, y_test = partition_data(data_frame, percentage)\n",
    "        data_frame = None\n",
    "        features_aar = None\n",
    "\n",
    "        #create svm\n",
    "        clf = svm.SVC(kernel=svm_kernel, class_weight=class_weights)\n",
    "        #fit model with training data\n",
    "        clf.fit(x_train,y_train)\n",
    "\n",
    "        #predict data\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        #Save the found model\n",
    "        n_bins = int(np.floor(100/bin_size))\n",
    "        path = \"Kernel_\" + svm_kernel + \"_Nbins_\" + str(n_bins) + \"_ClassWeights_\" + str(class_weights) + \"_\" + features_paths[i]\n",
    "        save_model(features_paths[i], clf)\n",
    "\n",
    "        #Save the results\n",
    "        results = \"Accuracy: \"+str(accuracy_score(y_test, y_pred)) + \"\\n\" + classification_report(y_test, y_pred)\n",
    "        save_results(results, path)\n",
    "        tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4915 0\n",
      "42769 0\n",
      "4915 1\n",
      "42769 1\n",
      "4915 2\n",
      "42769 2\n",
      "1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_3204\\310217235.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data_frame = np.array(data_frame)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m run_mult_models([features_paths[\u001b[39m0\u001b[39m]], names_paths, bin_size \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m, svm_kernel\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrbf\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [41], line 34\u001b[0m, in \u001b[0;36mrun_mult_models\u001b[1;34m(features_paths, names_paths, bin_size, svm_kernel, class_weights)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39m#partition data\u001b[39;00m\n\u001b[0;32m     33\u001b[0m percentage \u001b[39m=\u001b[39m \u001b[39m80\u001b[39m\n\u001b[1;32m---> 34\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m partition_data(data_frame, percentage)\n\u001b[0;32m     35\u001b[0m data_frame \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     36\u001b[0m features_aar \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [39], line 4\u001b[0m, in \u001b[0;36mpartition_data\u001b[1;34m(data_frame, percentage)\u001b[0m\n\u001b[0;32m      2\u001b[0m partition \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(data_frame)\u001b[39m*\u001b[39mpercentage\u001b[39m/\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(data_frame\u001b[39m.\u001b[39mshape), \u001b[39m2\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(data_frame[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape), \u001b[39m2\u001b[39m)\n\u001b[0;32m      5\u001b[0m x_train, x_test \u001b[39m=\u001b[39m data_frame[:partition,:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],  data_frame[partition:,:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m      6\u001b[0m y_train, y_test \u001b[39m=\u001b[39m data_frame[:partition,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mravel() , data_frame[partition:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mravel()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "run_mult_models([features_paths[0]], names_paths, bin_size = 10, svm_kernel=\"rbf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('imgp2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a6e5b842e2037657f728d9ad513cfa5a0314365ca8a86cdbfa2f5f3f58bdad7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
